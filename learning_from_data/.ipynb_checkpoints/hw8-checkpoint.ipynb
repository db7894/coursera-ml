{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"hw8.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20bd2c67b38>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"hw8.pdf\", width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[d]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a QP problem with $d+1$ variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python35\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'features.train'\n",
    "test_file = 'features.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):    \n",
    "    with open(filename, \"r\") as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                y, x1, x2 = line.split()\n",
    "                data.append([ int(float(y)), float(x1), float(x2) ])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data(train_file)\n",
    "data_test = load_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 0.01\n",
    "Q = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=C, kernel='poly', degree = Q, coef0 = 1.0, gamma = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_vs_all(k, data):\n",
    "    \"\"\"\n",
    "    k-vs-all: recall in 1-vs-all one digit has class +1 w/ rest -1.\n",
    "    k is just number k--so basically if the data pt has value k (e.g. 1, etc.) we label it with +1 in new y\n",
    "    \"\"\"\n",
    "    y = [data[i][0] for i in range(len(data))]\n",
    "    X = [[data[i][1], data[i][2]] for i in range(len(data))]\n",
    "    \n",
    "    y_new = []\n",
    "    ct = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == k:\n",
    "            y_new.append(1.0)\n",
    "            ct += 1\n",
    "        else:\n",
    "            y_new.append(-1.0)\n",
    "            \n",
    "    return y_new, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_vs_k(k1, k2, data):\n",
    "    \"\"\"\n",
    "    e.g. if 1 vs 5 call k_vs_k(1, 5, data)\n",
    "    \"\"\"\n",
    "    y = [data[i][0] for i in range(len(data))]\n",
    "    X = [[data[i][1], data[i][2]] for i in range(len(data))]\n",
    "    \n",
    "    y_new = []\n",
    "    X_new = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == k1:\n",
    "            y_new.append(1.0)\n",
    "            X_new.append(X[i])\n",
    "            \n",
    "        if y[i] == k2:\n",
    "            y_new.append(-1.0)\n",
    "            X_new.append(X[i])\n",
    "            \n",
    "    return y_new, X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphs_even = np.array([])\n",
    "alphs_odd = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-vs-all binary classifier in-sample error: 0.105884\n",
      "1-vs-all binary classifier in-sample error: 0.014401\n",
      "2-vs-all binary classifier in-sample error: 0.100261\n",
      "3-vs-all binary classifier in-sample error: 0.090248\n",
      "4-vs-all binary classifier in-sample error: 0.089425\n",
      "5-vs-all binary classifier in-sample error: 0.076258\n",
      "6-vs-all binary classifier in-sample error: 0.091071\n",
      "7-vs-all binary classifier in-sample error: 0.088465\n",
      "8-vs-all binary classifier in-sample error: 0.074338\n",
      "9-vs-all binary classifier in-sample error: 0.088328\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    y, X = k_vs_all(k, data_train)\n",
    "    svm.fit(X, y)\n",
    "    \n",
    "    score = svm.score(X, y)\n",
    "    num_alphas = svm.n_support_\n",
    "    alpha_sum = np.array(num_alphas).sum()\n",
    "    print(\"%d-vs-all binary classifier in-sample error: %f\" % (k, (1.0 - score)))\n",
    "    \n",
    "    if k % 2 == 0:\n",
    "        alphs_even = np.concatenate((alphs_even, [alpha_sum]))\n",
    "    else:\n",
    "        alphs_odd = np.concatenate((alphs_odd, [alpha_sum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in # Support Vectors between two classifiers: 2071\n"
     ]
    }
   ],
   "source": [
    "aodd_sum = np.sum(alphs_odd)\n",
    "aeven_sum = np.sum(alphs_even)\n",
    "a_diff = abs(aodd_sum - aeven_sum)\n",
    "print(\"Difference in # Support Vectors between two classifiers: %d\" % a_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[e]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from the above run, we see the best $k$-vs-all, that which has the lowest $E_{in}$, is $8$ versus all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[a]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again reading from the above, the best classifier is $1$-vs-all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[c]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above computation tells us the two models differ by $2071$ support vectors. This is closest to the answer $1800$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[d]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_1 = 2\n",
    "Q_2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_vals = [0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ein_2 = [] # Ein values for Q = 2, C ranging from 0.001 to 1\n",
    "Ein_5 = [] # Ein values for Q = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SV_2 = [] # num SVs when Q = 2, C ranging\n",
    "SV_5 = [] # num SVs when Q = 5, C ranging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas_2 = np.array([])\n",
    "alphas_5 = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-vs-5 classifier with C = 0.001000, Q = 2 in-sample error: 0.004484\n",
      "1-vs-5 classifier with C = 0.001000, Q = 2 out-sample error: 0.016509\n",
      "\n",
      "1-vs-5 classifier with C = 0.001000, Q = 5 in-sample error: 0.004484\n",
      "1-vs-5 classifier with C = 0.001000, Q = 5 out-sample error: 0.021226\n",
      "\n",
      "number of support vectors with C = 0.001000, Q = 2: 76\n",
      "number of support vectors with C = 0.001000, Q = 5: 25\n",
      "\n",
      "1-vs-5 classifier with C = 0.010000, Q = 2 in-sample error: 0.004484\n",
      "1-vs-5 classifier with C = 0.010000, Q = 2 out-sample error: 0.018868\n",
      "\n",
      "1-vs-5 classifier with C = 0.010000, Q = 5 in-sample error: 0.003844\n",
      "1-vs-5 classifier with C = 0.010000, Q = 5 out-sample error: 0.021226\n",
      "\n",
      "number of support vectors with C = 0.010000, Q = 2: 34\n",
      "number of support vectors with C = 0.010000, Q = 5: 23\n",
      "\n",
      "1-vs-5 classifier with C = 0.100000, Q = 2 in-sample error: 0.004484\n",
      "1-vs-5 classifier with C = 0.100000, Q = 2 out-sample error: 0.018868\n",
      "\n",
      "1-vs-5 classifier with C = 0.100000, Q = 5 in-sample error: 0.003203\n",
      "1-vs-5 classifier with C = 0.100000, Q = 5 out-sample error: 0.018868\n",
      "\n",
      "number of support vectors with C = 0.100000, Q = 2: 24\n",
      "number of support vectors with C = 0.100000, Q = 5: 25\n",
      "\n",
      "1-vs-5 classifier with C = 1.000000, Q = 2 in-sample error: 0.003203\n",
      "1-vs-5 classifier with C = 1.000000, Q = 2 out-sample error: 0.018868\n",
      "\n",
      "1-vs-5 classifier with C = 1.000000, Q = 5 in-sample error: 0.003203\n",
      "1-vs-5 classifier with C = 1.000000, Q = 5 out-sample error: 0.021226\n",
      "\n",
      "number of support vectors with C = 1.000000, Q = 2: 24\n",
      "number of support vectors with C = 1.000000, Q = 5: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in C_vals:\n",
    "    # get data\n",
    "    y, X = k_vs_k(1, 5, data_train)\n",
    "    y_out, X_out = k_vs_k(1, 5, data_test)\n",
    "    \n",
    "    # create SVMs\n",
    "    svm_2 = SVC(C=C, kernel='poly', degree = Q_1, coef0 = 1.0, gamma = 1.0)\n",
    "    svm_5 = SVC(C=C, kernel='poly', degree = Q_2, coef0 = 1.0, gamma = 1.0)\n",
    "    \n",
    "    # fit SVMs\n",
    "    svm_2.fit(X,y)\n",
    "    svm_5.fit(X,y)\n",
    "    \n",
    "    # get scores\n",
    "    score2 = svm_2.score(X,y)\n",
    "    score5 = svm_5.score(X,y)\n",
    "    \n",
    "    # get out-of-sample scores\n",
    "    score2_out = svm_2.score(X_out, y_out)\n",
    "    score5_out = svm_5.score(X_out, y_out)\n",
    "    \n",
    "    # convert to errors\n",
    "    err2 = 1.0 - score2\n",
    "    err5 = 1.0 - score5\n",
    "    \n",
    "    err2_out = 1.0 - score2_out\n",
    "    err5_out = 1.0 - score5_out\n",
    "    \n",
    "    print(\"1-vs-5 classifier with C = %f, Q = 2 in-sample error: %f\" % (C, err2))\n",
    "    print(\"1-vs-5 classifier with C = %f, Q = 2 out-sample error: %f\" % (C, err2_out))\n",
    "    print(\"\")\n",
    "    print(\"1-vs-5 classifier with C = %f, Q = 5 in-sample error: %f\" % (C, err5))\n",
    "    print(\"1-vs-5 classifier with C = %f, Q = 5 out-sample error: %f\" % (C, err5_out))\n",
    "    \n",
    "    # get num SVs\n",
    "    num_alphas2 = svm_2.n_support_\n",
    "    num_alphas5 = svm_5.n_support_\n",
    "    alphas2_sum = np.array(num_alphas2).sum()\n",
    "    alphas5_sum = np.array(num_alphas5).sum()\n",
    "    \n",
    "    # print num SVs\n",
    "    print(\"\")\n",
    "    print(\"number of support vectors with C = %f, Q = 2: %d\" % (C, alphas2_sum))\n",
    "    print(\"number of support vectors with C = %f, Q = 5: %d\" % (C, alphas5_sum))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we're looking for strictly going down or up. We can see that for $Q=2$, the in-sample error $E_{in}$ is achieved with the maximum value of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[b]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when $C = 0.01$, there are $25$ Support Vectors for the SVM with $Q=5$, as opposed to $76$ for the SVM with $Q=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_Q = 2\n",
    "cv_C = [pow(10,-x) for x in reversed(range(5))]\n",
    "cv_runs = 100 # num runs\n",
    "cv_splits = 10 # since doing 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits = cv_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_cvs = np.ndarray((0, len(cv_C)))\n",
    "cv_best = np.zeros(len(cv_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1v5, X_1v5 = k_vs_k(1,5,data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_1v5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1v5 = np.array(X_1v5)\n",
    "y_1v5 = np.array(y_1v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(cv_runs):\n",
    "    Ecvs = np.array([])\n",
    "    for C in cv_C:\n",
    "        svm.C = C\n",
    "        e_vals = np.array([]) # validation errors\n",
    "        \n",
    "        # go thru folds\n",
    "        for train_idx, test_idx in k_fold.split(X_1v5):\n",
    "            #print(train_idx)\n",
    "            cv_Xtrain, cv_Xtest = X_1v5[train_idx], X_1v5[test_idx]\n",
    "            cv_ytrain, cv_ytest = y_1v5[train_idx], y_1v5[test_idx]\n",
    "            svm.fit(cv_Xtrain, cv_ytrain)\n",
    "            \n",
    "            err = 1.0 - svm.score(cv_Xtest, cv_ytest)\n",
    "            e_vals = np.concatenate((e_vals, [err]))\n",
    "        \n",
    "        Ecv = np.average(e_vals)\n",
    "        Ecvs = np.concatenate((Ecvs, [Ecv]))\n",
    "        \n",
    "    best_idx = np.argmin(Ecvs) # index of best C\n",
    "    \n",
    "    # save best C\n",
    "    cv_best[best_idx] = cv_best[best_idx] + 1\n",
    "    \n",
    "    # add CV errors\n",
    "    e_cvs = np.vstack((e_cvs, Ecvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ecv_avg = np.average(e_cvs, axis=0) # get avg CV error\n",
    "best_overall = np.argmax(cv_best)\n",
    "Ecv_best = Ecv_avg[best_overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.001000 is selected most often with average E_cv 0.004483\n"
     ]
    }
   ],
   "source": [
    "print(\"C = %f is selected most often with average E_cv %f\" % (cv_C[best_overall], Ecv_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[b]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from the above, $C=0.001$ is selected most often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[c]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, reading from the above, for the winning selection, the average $E_{CV} = 0.004483$, which is closest to the answer choice $E_{CV} =  0.005$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[e]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll use X_1v5 and y_1v5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1v5_out, X1v5_out = k_vs_k(1,5,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1v5_out = np.array(y1v5_out)\n",
    "X1v5_out = np.array(X1v5_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_vals = [pow(10, x) for x in range(-2,8,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 1, 100, 10000, 1000000]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm.kernel = 'rbf'\n",
    "svm.gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.010000 | E_in = 0.003844, E_out = 0.023585\n",
      "C = 1.000000 | E_in = 0.004484, E_out = 0.021226\n",
      "C = 100.000000 | E_in = 0.003203, E_out = 0.018868\n",
      "C = 10000.000000 | E_in = 0.002562, E_out = 0.023585\n",
      "C = 1000000.000000 | E_in = 0.000641, E_out = 0.023585\n"
     ]
    }
   ],
   "source": [
    "for C in C_vals:\n",
    "    svm.C = C\n",
    "    svm.fit(X_1v5, y_1v5)\n",
    "    Ein = 1.0 - svm.score(X_1v5, y_1v5)\n",
    "    Eout = 1.0 - svm.score(X1v5_out, y1v5_out)\n",
    "    \n",
    "    print(\"C = %f | E_in = %f, E_out = %f\" % (C, Ein, Eout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from above $C = 10^6$ results in the lowest in-sample-error $E_{in}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[c]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again reading from the above results, the intermediate value $C = 100$ results in the lowest out-of-sample error $E_{out}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
