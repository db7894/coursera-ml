{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"hw6.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c7be8785c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"hw6.pdf\", width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[b]__\n",
    "\n",
    "If $ \\mathcal{H}' \\subset \\mathcal{H} $, then $\\mathcal{H}'$ is a less expressive hypothesis set. Thus, if there is deterministic noise already when we try to fit $f$ from the larger hypothesis set $\\mathcal{H}$, there will be even more noise when we use this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_dta():\n",
    "    with urllib.request.urlopen(\"http://work.caltech.edu/data/in.dta\") as fpin:\n",
    "        lines = fpin.read().splitlines()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "        values = [[float(value) for value in line.strip('\\n').split('\\r')[0].split()] for line in lines]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def out_dta():\n",
    "    fpin = urllib.request.urlopen(\"http://work.caltech.edu/data/out.dta\").read().decode('utf-8')\n",
    "    for line in fpin:\n",
    "        print(line)\n",
    "    # print([float(value) for value in line.strip('\\n').split('\\r')[0].split()] for line in fpin)\n",
    "    return [[float(value) for value in line.strip('\\n').split('\\r')[0].split()] for line in fpin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(point):\n",
    "    \"\"\"\n",
    "    point is of form (x,y) with x in R2\n",
    "    \"\"\"\n",
    "    return [1, point[0], point[1], point[0]**2, point[1]**2, point[0]*point[1], abs(point[0] - point[1]), abs(point[0] + point[1]), point[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformPoints(points):\n",
    "    transformedPoints = []\n",
    "    for point in points:\n",
    "        transformedPoints.append(transform(point))\n",
    "    return transformedPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearRegression(samplePoints):\n",
    "    X = []\n",
    "    y = []\n",
    "    y_location = len(samplePoints[0]) -1 # y's location is assumed to be the last element in the list\n",
    "    \n",
    "    # construct X, split y vals\n",
    "    for point in samplePoints:\n",
    "        X.append(np.array(point[:y_location]))\n",
    "        y.append(point[y_location])\n",
    "        \n",
    "    # convert to np\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_inv = np.linalg.pinv(X)\n",
    "    \n",
    "    # use w = X_inv * y one-shot learning\n",
    "    return X_inv.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regularizedLinearRegression(samplePoints, l):\n",
    "    \"\"\"\n",
    "    perform LR with regularization, where l is lambda\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    y_location = len(samplePoints[0]) -1 # y's location is assumed to be the last element in the list\n",
    "    \n",
    "    # construct X, split y vals\n",
    "    for point in samplePoints:\n",
    "        X.append(np.array(point[:y_location]))\n",
    "        y.append(point[y_location])\n",
    "        \n",
    "    weights = linearRegression(samplePoints) # get weights to use for regularization\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # get the regularized form of the inverse, taking the pseudo-inv of X + lambda/N * wTw\n",
    "    X_regInv = np.linalg.pinv(X + np.array(l / len(samplePoints) * weights.dot(weights)))\n",
    "    \n",
    "    return X_regInv.dot(y) # again using one-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Ein(weights, samplePoints):\n",
    "    \"\"\"\n",
    "    Returns E_in given weights, sample pts\n",
    "    Assumes samplePoints is a list of lists, last elment in each list\n",
    "    is the y value.\n",
    "    \"\"\"\n",
    "    errorCount = 0\n",
    "    y_loc = len(samplePoints[0]) - 1\n",
    "    for point in samplePoints:\n",
    "        if np.sign(np.dot(weights, point[:y_loc])) != point[y_loc]:\n",
    "            errorCount += 1\n",
    "            \n",
    "    return errorCount / float(len(samplePoints)) # return as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q2():\n",
    "    trainPoints = in_dta()\n",
    "    testPoints = out_dta()\n",
    "    \n",
    "    transformedTrain = transformPoints(trainPoints) # to train LR\n",
    "    transformedTest = transformPoints(testPoints) # to test weights\n",
    "    \n",
    "    weights = linearRegression(transformedTrain)\n",
    "    \n",
    "    print(\"E_in: {}, E_out: {}\".format(Ein(weights, transformedTrain), Ein(weights,  transformedTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q3(l):\n",
    "    trainPoints = in_dta()\n",
    "    testPoints = out_dta()\n",
    "    \n",
    "    transformedTrain = transformPoints(trainPoints) # to train LR\n",
    "    transformedTest = transformPoints(testPoints) # to test weights\n",
    "    \n",
    "    weights = regularizedLinearRegression(transformedTrain, l) # this time w/ regularization\n",
    "    \n",
    "    print(\"E_in: {}, E_out: {}\".format(Ein(weights, transformedTrain), Ein(weights,  transformedTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q5(low, high):\n",
    "    trainPoints = in_dta()\n",
    "    testPoints = out_dta()\n",
    "    \n",
    "    transformedTrain = transformPoints(trainPoints) # to train LR\n",
    "    transformedTest = transformPoints(testPoints) # to test weights\n",
    "    \n",
    "    for i in range(low, high+1):\n",
    "        e_out = Ein(regularizedLinearRegression(transformedTrain, 10**i), transformedTest)\n",
    "        print(\"k = {}, E_out = {}\".format(i, e_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'  -7.7947021e-01   8.3822138e-01   1.0000000e+00'\n",
      "b'   1.5563491e-01   8.9537743e-01   1.0000000e+00'\n",
      "b'  -5.9907703e-02  -7.1777995e-01   1.0000000e+00'\n",
      "b'   2.0759636e-01   7.5893338e-01   1.0000000e+00'\n",
      "b'  -1.9598312e-01  -3.7548716e-01  -1.0000000e+00'\n",
      "b'   5.8848947e-01  -8.4255381e-01   1.0000000e+00'\n",
      "b'   7.1985874e-03  -5.4831650e-01  -1.0000000e+00'\n",
      "b'   7.3883852e-01  -6.0339369e-01   1.0000000e+00'\n",
      "b'   7.0464808e-01  -2.0420052e-02   1.0000000e+00'\n",
      "b'   9.6992666e-01   6.4137120e-01  -1.0000000e+00'\n",
      "b'   4.3543099e-01   7.4477254e-01  -1.0000000e+00'\n",
      "b'  -8.4425822e-01   7.4235423e-01   1.0000000e+00'\n",
      "b'   5.9142471e-01  -5.4602118e-01   1.0000000e+00'\n",
      "b'  -6.9093124e-02   3.7659995e-02  -1.0000000e+00'\n",
      "b'  -9.5154865e-01  -7.3305502e-01  -1.0000000e+00'\n",
      "b'  -1.2988138e-01   7.5676096e-01   1.0000000e+00'\n",
      "b'  -4.9534647e-01  -5.6627908e-01  -1.0000000e+00'\n",
      "b'  -9.0399413e-01   5.0922150e-01   1.0000000e+00'\n",
      "b'   2.9235128e-01   1.6089015e-01  -1.0000000e+00'\n",
      "b'   6.4798552e-01  -7.7933769e-01   1.0000000e+00'\n",
      "b'   3.7595574e-01   7.8203087e-02  -1.0000000e+00'\n",
      "b'   2.4588993e-01   4.5146739e-03  -1.0000000e+00'\n",
      "b'  -4.5719155e-01   4.2390461e-01   1.0000000e+00'\n",
      "b'  -4.4127876e-01   7.0571892e-01   1.0000000e+00'\n",
      "b'   5.0744669e-01   7.5872586e-01  -1.0000000e+00'\n",
      "b'  -1.3258381e-01  -5.8178837e-01  -1.0000000e+00'\n",
      "b'  -4.4749067e-01   1.9576364e-01   1.0000000e+00'\n",
      "b'   8.1658199e-01  -4.5449182e-01   1.0000000e+00'\n",
      "b'  -9.4422408e-01   8.8273421e-01   1.0000000e+00'\n",
      "b'   4.6265533e-01   3.5583605e-01  -1.0000000e+00'\n",
      "b'   8.8311642e-01  -1.9930013e-01   1.0000000e+00'\n",
      "b'   1.0016050e+00   5.2575476e-01  -1.0000000e+00'\n",
      "b'   6.0370095e-01  -5.4553701e-01   1.0000000e+00'\n",
      "b'  -1.4858757e-01  -2.1308372e-01  -1.0000000e+00'\n",
      "b'   1.1652163e-02   8.8923931e-01   1.0000000e+00'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-e98144b689ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-06c2cd21db19>\u001b[0m in \u001b[0;36mq2\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mq2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrainPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_dta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtestPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_dta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtransformedTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainPoints\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# to train LR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-ac28ad733def>\u001b[0m in \u001b[0;36min_dta\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-ac28ad733def>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "q2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = '  -7.7947021e-01   8.3822138e-01   1.0000000e+00\\r\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = line.strip('\\n').split('\\r')[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-7.7947021e-01', '8.3822138e-01', '1.0000000e+00']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.77947021\n",
      "0.83822138\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for value in values:\n",
    "    print(float(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[c]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristically, what the constraint is saying is that for all weights $w_q$ corresponding to variables of a degree higher than $Q_0$, we want to set those weights to the value $C$.\n",
    "\n",
    "We can see that if we take the intersection of the constraint that squashes all weights for degree $3$ or higher and that which zeros all weights corresponding to degree $4$ or higher, we just get the hypothesis space $\\mathcal{H}_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 18 operations for the 1-0 layer and 4 operations for the 2-1 layer which adds up to $22$ for the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[a]__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the max number of nodes, we want to connect every node to every node in the next layer. Also, with $36$ hidden units we have some leeway in how we construct our network--we can place them all in a single layer, or do something like create $6$ layers with $6$ neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
